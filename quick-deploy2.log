
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Zero-Day Detection & Mitigation Framework - Quick Deploy      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š System: 3493MB available â†’ Minikube: 3072MB, 2 CPUs

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 1: Start Minikube Cluster
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Minikube already running
Verifying cluster...
Kubernetes control plane is running at https://127.0.0.1:62093
CoreDNS is running at https://127.0.0.1:62093/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
NAME       STATUS   ROLES           AGE   VERSION
minikube   Ready    control-plane   19m   v1.28.0
âœ… Cluster ready

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 2: Apply Kubernetes Manifests
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¦ Creating namespaces...
namespace/prod unchanged
namespace/dev unchanged
namespace/monitoring unchanged
namespace/quarantine unchanged
namespace/ml unchanged
ğŸ” Applying RBAC...
serviceaccount/telemetry-collector unchanged
role.rbac.authorization.k8s.io/telemetry-reader unchanged
rolebinding.rbac.authorization.k8s.io/telemetry-reader-binding unchanged
serviceaccount/containment-operator unchanged
clusterrole.rbac.authorization.k8s.io/containment-operator-role unchanged
clusterrolebinding.rbac.authorization.k8s.io/containment-operator-binding unchanged
ğŸš« Applying Network Policies...
networkpolicy.networking.k8s.io/default-deny-all unchanged
networkpolicy.networking.k8s.io/allow-from-ingress unchanged
networkpolicy.networking.k8s.io/restrict-egress unchanged
ğŸ“‹ Applying Containment CRD...
customresourcedefinition.apiextensions.k8s.io/containments.security.example.com unchanged
âœ… Manifests applied

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 3: Deploy Core Telemetry (Simplified)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Deploying OpenTelemetry Collector...
configmap/otel-collector-config unchanged
deployment.apps/otel-collector unchanged
ğŸ“ Deploying Fluent Bit...
configmap/fluent-bit-config unchanged
daemonset.apps/fluent-bit unchanged
âœ… Core telemetry deployed

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 4: Build Container Images
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ³ Building services (skipping heavy ML image build)...
#0 building with "default" instance using docker driver

#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 239B done
#1 DONE 0.0s

#2 [internal] load metadata for docker.io/library/python:3.11-slim
#2 DONE 0.0s

#3 [internal] load .dockerignore
#3 transferring context: 2B done
#3 DONE 0.0s

#4 [internal] load build context
#4 transferring context: 353B done
#4 DONE 0.0s

#5 [1/5] FROM docker.io/library/python:3.11-slim@sha256:fa9b525a0be0c5ae5e6f2209f4be6fdc5a15a36fed0222144d98ac0d08f876d4
#5 resolve docker.io/library/python:3.11-slim@sha256:fa9b525a0be0c5ae5e6f2209f4be6fdc5a15a36fed0222144d98ac0d08f876d4 0.0s done
#5 DONE 0.0s

#6 [2/5] WORKDIR /app
#6 CACHED

#7 [3/5] COPY requirements.txt ./
#7 CACHED

#8 [4/5] RUN pip install --no-cache-dir -r requirements.txt
#8 CACHED

#9 [5/5] COPY src/ ./src/
#9 CACHED

#10 exporting to image
#10 exporting layers done
#10 exporting manifest sha256:1e5fa57d4c3f852344b8726e0b47e1d57052526bc1af8e3863c7bfcd9dd67405 done
#10 exporting config sha256:433143c0cee38291b75bd348620197b016f806449360f99ba928fcf5640f8998 done
#10 exporting attestation manifest sha256:196266508954340ba0bd3034c667e1bdf19a60e00f55ebd02bcd779bc49b2531 0.0s done
#10 exporting manifest list sha256:b05b6ce82c57d93b974ed1b6515973727f3d60d9e5620f730a9cfdd0980446b4 0.0s done
#10 naming to docker.io/library/graph-builder:latest done
#10 unpacking to docker.io/library/graph-builder:latest 0.0s done
#10 DONE 0.1s
  â†’ graph-builder built
#0 building with "default" instance using docker driver

#1 [internal] load build definition from Dockerfile.inference
#1 transferring dockerfile: 277B done
#1 DONE 0.0s

#2 [internal] load metadata for docker.io/library/python:3.11-slim
#2 DONE 0.0s

#3 [internal] load .dockerignore
#3 transferring context: 2B done
#3 DONE 0.0s

#4 [internal] load build context
#4 transferring context: 36.30kB done
#4 DONE 0.0s

#5 [1/5] FROM docker.io/library/python:3.11-slim@sha256:fa9b525a0be0c5ae5e6f2209f4be6fdc5a15a36fed0222144d98ac0d08f876d4
#5 resolve docker.io/library/python:3.11-slim@sha256:fa9b525a0be0c5ae5e6f2209f4be6fdc5a15a36fed0222144d98ac0d08f876d4 0.0s done
#5 DONE 0.0s

#6 [2/5] WORKDIR /app
#6 CACHED

#7 [3/5] COPY ml/requirements.txt ./
#7 CACHED

#8 [4/5] RUN pip install --no-cache-dir flask kubernetes -r requirements.txt
#8 1.560 Collecting flask
#8 1.621   Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)
#8 1.670 Collecting kubernetes
#8 1.685   Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)
#8 1.763 Collecting torch>=2.0.0 (from -r requirements.txt (line 1))
#8 1.778   Downloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)
#8 1.823 Collecting torch-geometric (from -r requirements.txt (line 2))
#8 1.837   Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)
#8 1.854      â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 63.7/63.7 kB 5.8 MB/s eta 0:00:00
#8 1.880 Collecting torch-scatter (from -r requirements.txt (line 3))
#8 1.895   Downloading torch_scatter-2.1.2.tar.gz (108 kB)
#8 1.915      â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 108.0/108.0 kB 6.2 MB/s eta 0:00:00
#8 1.946   Preparing metadata (setup.py): started
#8 2.313   Preparing metadata (setup.py): finished with status 'error'
#8 2.316   error: subprocess-exited-with-error
#8 2.316   
#8 2.316   Ã— python setup.py egg_info did not run successfully.
#8 2.316   â”‚ exit code: 1
#8 2.316   â•°â”€> [6 lines of output]
#8 2.316       Traceback (most recent call last):
#8 2.316         File "<string>", line 2, in <module>
#8 2.316         File "<pip-setuptools-caller>", line 34, in <module>
#8 2.316         File "/tmp/pip-install-zfx1i5xa/torch-scatter_fbd14983a8d645a3a056e96ef5d3fac7/setup.py", line 8, in <module>
#8 2.316           import torch
#8 2.316       ModuleNotFoundError: No module named 'torch'
#8 2.316       [end of output]
#8 2.316   
#8 2.316   note: This error originates from a subprocess, and is likely not a problem with pip.
#8 2.317 error: metadata-generation-failed
#8 2.317 
#8 2.317 Ã— Encountered error while generating package metadata.
#8 2.317 â•°â”€> See above for output.
#8 2.317 
#8 2.317 note: This is an issue with the package mentioned above, not pip.
#8 2.317 hint: See above for details.
#8 2.439 
#8 2.439 [notice] A new release of pip is available: 24.0 -> 25.3
#8 2.439 [notice] To update, run: pip install --upgrade pip
#8 ERROR: process "/bin/sh -c pip install --no-cache-dir flask kubernetes -r requirements.txt" did not complete successfully: exit code: 1
------
 > [4/5] RUN pip install --no-cache-dir flask kubernetes -r requirements.txt:
2.317 error: metadata-generation-failed
2.317 
2.317 Ã— Encountered error while generating package metadata.
2.317 â•°â”€> See above for output.
2.317 
2.317 note: This is an issue with the package mentioned above, not pip.
2.317 hint: See above for details.
2.439 
2.439 [notice] A new release of pip is available: 24.0 -> 25.3
2.439 [notice] To update, run: pip install --upgrade pip
------
Dockerfile.inference:4
--------------------
   2 |     WORKDIR /app
   3 |     COPY ml/requirements.txt ./
   4 | >>> RUN pip install --no-cache-dir flask kubernetes -r requirements.txt
   5 |     COPY ml/src/ ./src/
   6 |     ENV PYTHONPATH=/app/src
--------------------
ERROR: failed to build: failed to solve: process "/bin/sh -c pip install --no-cache-dir flask kubernetes -r requirements.txt" did not complete successfully: exit code: 1
  â†’ inference build failed
  â†’ containment-operator build failed
âœ… Image build step complete (ml image skipped). To build ML image, run: docker build -t ml:latest ml/

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 5: Load Images into Minikube
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¥ Loading images (ml image skipped)...
! The image 'inference:latest' was not found; unable to add it to cache.
! The image 'containment-operator:latest' was not found; unable to add it to cache.
âœ… Images loaded

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 6: Deploy Microservices
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¦ Deploying services...
serviceaccount/graph-builder created
role.rbac.authorization.k8s.io/graph-builder-role created
rolebinding.rbac.authorization.k8s.io/graph-builder-binding created
deployment.apps/graph-builder created
serviceaccount/ml-trainer created
role.rbac.authorization.k8s.io/ml-trainer-role created
rolebinding.rbac.authorization.k8s.io/ml-trainer-binding created
cronjob.batch/ml-trainer created
serviceaccount/inference created
role.rbac.authorization.k8s.io/inference-role created
rolebinding.rbac.authorization.k8s.io/inference-binding created
deployment.apps/inference-service created
service/inference created
deployment.apps/containment-operator created
â³ Waiting for deployments... (60 seconds)
âœ… Services deployed

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 7: Verify Deployment Status
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ Pod status:
kube-system   coredns-5dd5756b68-fnbbn               1/1   Running            0             20m
kube-system   etcd-minikube                          1/1   Running            0             20m
kube-system   kube-apiserver-minikube                1/1   Running            0             20m
kube-system   kube-controller-manager-minikube       1/1   Running            0             20m
kube-system   kube-proxy-h7grv                       1/1   Running            0             20m
kube-system   kube-scheduler-minikube                1/1   Running            0             20m
kube-system   storage-provisioner                    1/1   Running            0             20m
ml            graph-builder-5cd8fd4d54-95xhz         0/1   Error              3 (37s ago)   62s
ml            inference-service-d6f47ccdf-zrr99      0/1   ImagePullBackOff   0             61s
monitoring    fluent-bit-dztvv                       0/1   ImagePullBackOff   0             20m
monitoring    otel-collector-65cf4d87cf-pgmgk        1/1   Running            0             20m
quarantine    containment-operator-8fbd99fd6-h95bh   0/1   ImagePullBackOff   0             61s

âœ… Deployment verification complete

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STEP 8: Quick Inference Test (Optional)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Testing inference service...
âœ… Inference service deployed

To test manually, run:
  kubectl -n ml port-forward svc/inference 8080:8080 &
  sleep 2
  curl -X POST http://localhost:8080/health


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… DEPLOYMENT COMPLETE!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Next Steps:

1ï¸âƒ£  Verify cluster:
    kubectl get all -A

2ï¸âƒ£  Train ML models locally:
    cd /home/wini/zero-day
    make train-ml-full

3ï¸âƒ£  Test inference service:
    make test-inference

4ï¸âƒ£  View Grafana dashboards:
    minikube service grafana -n monitoring || echo 'Grafana not installed'

5ï¸âƒ£  Read operational runbook:
    cat docs/RUNBOOK.md

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

